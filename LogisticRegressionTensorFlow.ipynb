{"cells":[{"metadata":{},"cell_type":"markdown","source":"Install tensorflow package. \n\nNote: Turn on internet toggle from Settings panel located on the right"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"!pip install tensorflow==2.0.0-alpha0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import OneHotEncoder ","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"read in the data. this was written on the kaggle platform so we can use the dataset directly without downloading it"},{"metadata":{"trusted":true},"cell_type":"code","source":"banknotes = pd.read_csv(\"/kaggle/input/banknote-detection-authentication/data_banknote_authentication.txt\",\n                        names = [\"Variance\", \"Skewness\", \"Curtosis\", \"Entropy\", \"TargetClass\"])","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"separate dataset into features and target"},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate independent variables\nx_orig = banknotes.iloc[:, 0:-1].values \n  \n# get the target class\ny_orig = banknotes.iloc[:, -1:].values ","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"onehotencode our target class. set the training parameters such as learning rate and epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"\noneHot = OneHotEncoder() \n  \n\noneHot.fit(y_orig) \ny = oneHot.transform(y_orig).toarray() \n\nx = x_orig\n\n  \nalpha, epochs = 0.0035, 1000\nm, n = x.shape ","execution_count":4,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"must define input graphs, weight, and bias"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of independent variables n\nX = tf.placeholder(tf.float32, [None, n]) \n  \n# For binary classification, we only have 2 possible outcomes\nY = tf.placeholder(tf.float32, [None, 2]) \n  \n# Model weights \nW = tf.Variable(tf.zeros([n, 2])) \n  \n# Model bias\nb = tf.Variable(tf.zeros([2])) ","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"some more setup functions are required such as the hypothesis, cost function, optimizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hypothesis \nY_hat = tf.nn.sigmoid(tf.add(tf.matmul(X, W), b)) \n  \n# Sigmoid Cross Entropy Cost Function \n\ncost = tf.nn.sigmoid_cross_entropy_with_logits( \n                    logits = Y_hat, labels = Y) \n  \n# Gradient Descent Optimizer \noptimizer = tf.train.GradientDescentOptimizer( \n         learning_rate = alpha).minimize(cost) \n  \n# Global Variables Initializer \ninit = tf.global_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the training session begins"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwith tf.Session() as sess: \n\n    sess.run(init) \n      \n    # Lists for storing the changing Cost and Accuracy in every Epoch \n    cost_history, accuracy_history = [], [] \n      \n    # Iterating through all the epochs \n    for epoch in range(epochs): \n        cost_per_epoch = 0\n          \n        # Running the Optimizer \n        sess.run(optimizer, feed_dict = {X : x, Y : y}) \n          \n        # Calculating cost on current Epoch \n        c = sess.run(cost, feed_dict = {X : x, Y : y}) \n        \n        # Calculating accuracy on current Epoch \n        correct_prediction = tf.equal(tf.argmax(Y_hat, 1), \n                                          tf.argmax(Y, 1)) \n        \n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \n                                                 tf.float32)) \n          \n        # Storing Cost and Accuracy to the history \n        cost_history.append(sum(sum(c))) \n        accuracy_history.append(accuracy.eval({X : x, Y : y}) * 100) \n          \n        # Displaying result on current Epoch \n        if epoch % 100 == 0 and epoch != 0: \n            print(\"Epoch \" + str(epoch) + \" Cost: \"\n                            + str(cost_history[-1])) \n      \n    Weight = sess.run(W) # Optimized Weight\n    Bias = sess.run(b)   # Optimized Bias\n      \n    # Final Accuracy \n    correct_prediction = tf.equal(tf.argmax(Y_hat, 1), \n                                      tf.argmax(Y, 1)) \n    \n    accuracy = tf.reduce_mean(tf.cast(correct_prediction,  \n                                             tf.float32)) \n    print(\"\\nAccuracy:\", accuracy_history[-1], \"%\") ","execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'init' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-68665173d176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Lists for storing the changing Cost and Accuracy in every Epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'init' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"plot the cost per epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(list(range(epochs)), cost_history) \nplt.xlabel('Epochs') \nplt.ylabel('Cost') \nplt.title('Cost Per Epoch') \n\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot the accuracy per epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(list(range(epochs)), accuracy_history) \nplt.xlabel('Epochs') \nplt.ylabel('Accuracy') \nplt.title('Accuracy Per Epoch') \n  \nplt.show() ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}